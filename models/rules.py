from sklearn.cluster import KMeans
from scipy.spatial.distance import cdist
import torch
import abc
from kmeans_pytorch import kmeans


class RuleBase(object):
    """
    this is the base class of rules which is generated by cluster methods
    """
    def __init__(self):
        """
        n_rules: the number of rules, namely the number of cluster centers
        center_list: the list of cluster centers
        consequent_list: list of consequent layer
        widths_list: standard deviation of each clusters
        """
        self.n_rules = 0
        self.center_list = None
        self.consequent_list = None
        self.widths_list = None

    @abc.abstractmethod
    def fit(self, x, n_rules=5):
        """
        todo initiate the rule class, actually, rules are initially constructed by
         a combination of cluster center, std and labels
        :param x: the data where rules are generated
        :param n_rules: number of the rules, namely the number of cluster centers
        """
        self.n_rules = n_rules

    @abc.abstractmethod
    def update_rules(self, x, center):
        """
        todo: update rule object according to the given cluster center list
        :param x: the data where rules are generated
        :param center: the given cluster center list
        :return: None
        """
        pass

    @abc.abstractmethod
    def update_center(self, x):
        """
        todo: generate new centers upon current rule data. use x label list to get
        new cluster centers under kmeans, use partition matrix to get new fuzzy centers
        :param x: the data where rules are generated
        :return: None
        """
        new_center = []
        return new_center


class RuleKmeans(RuleBase):
    def __init__(self):
        """
        x_center_idx: the labels of which center traning data belongs to
        """
        super(RuleKmeans, self).__init__()
        self.x_center_idx = None

    def fit(self, x, n_rules=5):
        """
        todo initiate the rule class, actually, rules are initially constructed by
         a combination of cluster center, std and labels
        :param x: the data where rules are generated
        :param n_rules: number of the rules, namely the number of cluster centers
        """
        cluster_ids_x, cluster_centers = kmeans(
            X=x, num_clusters=n_rules, distance='euclidean', device=torch.device(x.device)
        )
        # kmeans = KMeans(n_clusters=n_rules, init="random", random_state=420).fit(x)
        self.n_rules = n_rules
        # self.center_list = torch.tensor(kmeans.cluster_centers_).float()
        self.center_list = cluster_centers.to(x.device)
        self.consequent_list = None
        # self.x_center_idx = torch.tensor(kmeans.labels_)
        self.x_center_idx = cluster_ids_x.to(x.device)
        self.widths_list = self.get_widths_list(x)

    def get_widths_list(self, x):
        """
        todo  get standard deviation of each clusters
        :param x: the data where rules are generated
        :return std: standard deviation of each clusters
        """
        # get the std of data x
        std = torch.empty((0, x.shape[1])).to(x.device)
        for i in range(self.n_rules):
            mask = self.x_center_idx == i
            cluster_samples = x[mask]
            std_tmp = torch.sqrt(torch.sum((cluster_samples-self.center_list[i, :])**2, 0)/ torch.tensor(cluster_samples.shape[0]).float())
            # std_tmp = torch.std(cluster_samples, 0).unsqueeze(0)
            std = torch.cat((std, std_tmp.unsqueeze(0)), 0)
            if not torch.where(std_tmp == 0)[0].shape[0] == 0:
                print('there is some centroid arranged with no sample')
        return std

    def update_rules(self, x, center):
        """
        todo: update rule object according to the given cluster center list
        :param x: the data where rules are generated
        :param center: the given cluster center list
        :return: None
        """
        self.center_list = center
        self.n_rules = center.shape[0]
        x_dist = torch.tensor(cdist(x, center)).to(x.device)
        center_idx = torch.argmin(x_dist, 1)
        self.x_center_idx = center_idx
        self.widths_list = self.get_widths_list(x)

    def update_center(self, x):
        """
        todo: generate new centers upon current rule data. use x label list to get
        new cluster centers under kmeans, use partition matrix to get new fuzzy centers
        :param x: the data where rules are generated
        :return: None
        """
        new_center = torch.zeros((self.center_list.shape[0], self.center_list.shape[1])).to(x.device)
        for k in torch.arange(self.n_rules):
            label_ids = torch.where(self.x_center_idx == k)
            # if no sample is related to this center
            if not label_ids[0].shape[0] == 0:
                smpl_k = x[label_ids[0], :]
                new_center[k, :] = smpl_k.mean(0)
            else:
                new_center[k, :] = self.center_list[k, :]

        return new_center


# class RuleFuzzyCmeans(RuleKmeans):
#     """
#     todo: use fuzzy c means to generate rules
#     """
#     def __init__(self):
#         """
#         center_list: the list of cluster centers
#         x_center_idx: the labels of which center traning data belongs to
#         consequent_list: list of consequent layer
#         widths_list: standard deviation of each clusters
#         """
#         super(RuleFuzzyCmeans, self).__init__()
#         self.para_h = 1
#         self.data_partition: torch.Tensor = None
#
#     def fit(self, x, n_rules=5):
#         """
#         todo initiate the rule class, actually, rules are initially constructed by
#          a combination of cluster center, std and labels
#         :param x: the data where rules are generated
#         :param n_rules: number of the rules, namely the number of cluster centers
#         """
#         center_list, data_partition, _, _, _, _, _ = \
#             cmeans(x.t(), n_rules, 2, error=0.005, maxiter=1000)
#         self.n_rules = n_rules
#         self.center_list = torch.tensor(center_list)
#         self.data_partition = torch.tensor(data_partition).t()
#         self.consequent_list = None
#         self.widths_list = self.get_widths_list(x)
#
#     def get_widths_list(self, x: torch.Tensor):
#         """
#         todo  get standard deviation of each clusters
#         :param x: the data where rules are generated
#         :return std: standard deviation of each clusters
#         """
#         center_std = torch.zeros((self.center_list.shape[0], self.center_list.shape[1]))
#         for k in torch.arange(self.n_rules):
#             part_rule = self.data_partition[:, k]
#             part_rule = part_rule.unsqueeze(1).float()
#             part_rule_exp = part_rule.repeat(1, x.shape[1])
#
#             center_k = self.center_list[k, :]
#             center_k = center_k.unsqueeze(0).float()
#             center_k_exp = center_k.repeat(x.shape[0], 1)
#
#             x_var = (x - center_k_exp).pow(2)
#             center_k_var = torch.mul(x_var, part_rule_exp).sum(0) / part_rule_exp.sum(0)
#             center_k_var = self.para_h * center_k_var
#             center_k_std = center_k_var.sqrt()
#             center_std[k, :] = center_k_std
#
#         return center_std
#
#     def update_rules(self, x: torch.Tensor, center):
#         """
#         todo: update rule object according to the given cluster center list
#         :param x: the data where rules are generated
#         :param center: the given cluster center list
#         :return: None
#         """
#         self.center_list = center
#         self.n_rules = center.shape[0]
#         data_partition, _, _, _, _, _ = \
#             cmeans_predict(x.t(), center, 2, error=0.005, maxiter=1000)
#         self.data_partition = torch.tensor(data_partition).t()
#         self.widths_list = self.get_widths_list(x)
#
#     def update_center(self, x):
#         """
#         todo: generate new centers upon current rule data. use x label list to get
#         new cluster centers under kmeans, use partition matrix to get new fuzzy centers
#         :param x: the data where rules are generated
#         :return: None
#         """
#         new_center = torch.zeros((self.center_list.shape[0], self.center_list.shape[1]))
#         for k in torch.arange(self.n_rules):
#             part_rule = self.data_partition[:, k]
#             part_rule = part_rule.unsqueeze(1).float()
#             part_rule_exp = part_rule.repeat(1, x.shape[1])
#
#             center_k = torch.mul(x, part_rule_exp).sum(0) / part_rule_exp.sum(0)
#             new_center[k, :] = center_k
#
#         return new_center
